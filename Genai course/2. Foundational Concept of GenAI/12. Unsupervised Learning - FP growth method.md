## 📘 What is Association Rule Mining?

Association rule mining is an **unsupervised learning technique** that finds **relationships between items** in a dataset.
### 💡 Think:

> “People who buy bread often also buy butter.”

This is useful when you want to find **patterns of co-occurrence**.


![](/images/Pasted image 20250609155909.png)

## 🔥 What is FP-Growth?

FP-Growth = **Frequent Pattern Growth algorithm**

- It is **faster and more efficient** than Apriori
- Builds a **tree (FP-Tree)** to store transactions
- **Avoids scanning the database again and again** like Apriori does

🧠 **Memory Tip**: FP-Growth = **Fast Pattern mining**


## 📦 Use Cases

| Domain                        | Example                                                      |
| ----------------------------- | ------------------------------------------------------------ |
| 🛒 **Market Basket Analysis** | “If a customer buys milk, what else are they likely to buy?” |
| 🌐 **Web Usage Mining**       | “What pages do people often visit together?”                 |
| 🧬 **Bio/Medical Research**   | Genes or symptoms that co-occur                              |
## 🔍 How FP-Growth Works (explained from image)

### Step-by-step:

1. **Create a frequency table**  
    Count how often each item appears. (B: 3, M: 3, etc.)
    
2. **Build FP-Tree**  
    Add transactions in tree format, reusing branches (like a trie data structure)
    
3. **Extract frequent patterns**
    - Based on a support threshold (e.g. support ≥ 2)
    - These patterns become association rules
        
4. **Generate Rules**
    - “If A → B” with metrics like **support, confidence, lift**


## 📐 Key Concepts in Diagram

| Concept                   | Simple Meaning                                        |
| ------------------------- | ----------------------------------------------------- |
| **Support**               | How often an itemset appears in the data              |
| **FP-Tree**               | Tree structure that stores compressed info            |
| **Root**                  | Starting point of the tree                            |
| **Threshold support = 2** | Only items that appear 2 or more times are considered |

🧠 In your image:

- You have transactions in tabular form
- Build frequency table
- FP-Tree is shown growing step-by-step
- Then generate association rules (like B → M, B → M + J, etc.)


## ✅ Assumptions

| Assumption                        | Meaning                                                                  |
| --------------------------------- | ------------------------------------------------------------------------ |
| 📊 **Tabular Data Format**        | Data should be in transaction format (rows = purchases, columns = items) |
| 💽 **Transactional-type dataset** | Like invoices, product IDs, logs                                         |

## 🛠 When to Use FP-Growth

|Use FP-Growth When...|Why|
|---|---|
|✅ **You have a large transactional dataset**|Fast and memory efficient|
|❌ **You don’t want to scan data repeatedly**|FP-Growth scans once and builds tree|
|✅ **You want patterns, not predictions**|It’s for discovering “what goes with what,” not classifying|

## ⚖️ FP-Growth vs Apriori

|Feature|Apriori|FP-Growth|
|---|---|---|
|Data Scans|Multiple|Only 2|
|Speed|Slower|Faster|
|Memory|Less|More (stores tree)|
|Use When|Small data|Large data|

## 📌 Example Rule

**“B → M + J”**  
→ This means:

> If customer buys B (say, bread), they are also likely to buy M (milk) and J (jam)

This rule is useful in:
- Product bundling
- Recommender systems








